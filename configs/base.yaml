prompt:
  system_prompt: "당신은 유용한 AI 어시스턴트입니다."
  input_prompt: "문서를 보고 대답해주세요
  ### 문서 : {문서}
  ### 질문 : {질문}"

model:
  device_count: 2
  model_name: "Qwen/Qwen2.5-1.5B"
  vllm_config:
    max_model_len: 4096
    tensor_parallel_size: 2 # device_count와 같은 정수값 또는 사용하고싶은 GPU 개수
    gpu_memory_utilization: 0.9
    enforce_eager: True
    dtype: "bfloat16"
    # enable_lora: False  # When using LoRA Adapter
    # max_lora_rank: 64   # When using LoRA Adapter

data: 
  data_path: './data/sample.xlsx'
  save_path: './output'
  save_type: 'csv'

generate:
  use_chat: True
  vllm_gen_config: {
        "max_tokens": 1024,
        "temperature": 0,
        "top_p": 1.0,
        "stop": ["Instruction:", "Instruction", "Response:", "Response","<|eot_id|>"]
    }