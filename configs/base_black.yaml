prompt:
  system_prompt: "당신은 유용한 AI 어시스턴트입니다."
  input_prompt: "문서를 보고 대답해주세요
  ### 문서 : {문서}
  ### 질문 : {질문}"

model:
  type: "black_box" # "black_box", "white_box" / "black_box" refers to API generation like OpenAI's GPT API or Claude3, and "white_box" refers to open-source or local LLMs
  model_name: "openai/gpt-4o-mini"
  api_key: "sk-your API Key"
  vllm_config:
    max_model_len: 4096
    tensor_parallel_size: 2 # device_count와 같은 정수값 또는 사용하고싶은 GPU 개수
    gpu_memory_utilization: 0.9
    enforce_eager: True
    dtype: "bfloat16"
    # enable_lora: False  # When using LoRA Adapter
    # max_lora_rank: 64   # When using LoRA Adapter

data: 
  data_path: './data/sample.xlsx'
  save_path: './output'
  save_type: 'excel'

generate:
  use_chat: False
  vllm_gen_config: {
        "max_tokens": 1024,
        "temperature": 0,
        "top_p": 1.0,
        "stop": ["Instruction:", "Instruction", "Response:", "Response","<|eot_id|>"]
    }